{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0b728ec-ede1-4395-863a-7679d93651e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# regression performance evaluation metrics\n",
    "\n",
    "# 1. Mean Squared Error (MSE)\n",
    "# MSE measures the average of the squares of the errors — the difference between actual (y_true) and predicted (y_pred) values.\n",
    "\n",
    "# Characteristics:\n",
    "\n",
    "# Squaring penalizes large errors more than small errors.\n",
    "\n",
    "# Sensitive to outliers.\n",
    "\n",
    "# Units = square of the target variable units.\n",
    "\n",
    "# 2. Root Mean Squared Error (RMSE)\n",
    "# RMSE is simply the square root of MSE. It brings the error metric back to the same unit as the target variable.\n",
    "# Characteristics:\n",
    "\n",
    "# Like MSE, penalizes large errors more heavily.\n",
    "\n",
    "# Easier to interpret than MSE because it's in the same unit as the target variable.\n",
    "\n",
    "# 3. Mean Absolute Error (MAE)\n",
    "\n",
    "# Definition:\n",
    "# MAE is the average of the absolute differences between actual and predicted values.\n",
    "\n",
    "# Characteristics:\n",
    "\n",
    "# Measures average magnitude of errors.\n",
    "\n",
    "# Less sensitive to outliers than MSE/RMSE.\n",
    "\n",
    "# Units = same as the target variable.\n",
    "\n",
    "# 4. R-squared Score (R² Score)\n",
    "\n",
    "# Definition:\n",
    "# R² measures how much of the variance in the dependent variable is explained by the model.\n",
    "\n",
    "# Interpretation:\n",
    "\n",
    "# R² = 1 → perfect prediction\n",
    "\n",
    "# R² = 0 → model predicts no better than mean\n",
    "\n",
    "# R² < 0 → model worse than mean\n",
    "\n",
    "# 5. Adjusted R-squared\n",
    "\n",
    "# Definition:\n",
    "# Adjusted R² adjusts R² for the number of predictors in the model. Useful when you have multiple features because R² always increases with more features, even if they’re irrelevant.\n",
    "\n",
    "# Interpretation:\n",
    "\n",
    "# Penalizes unnecessary features.\n",
    "\n",
    "# Can decrease if irrelevant features are added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ff1e73-d64b-47f8-a06e-42541eafa8d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48247410-104f-48d2-b739-66ff0811ae79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scenario\tRecommended Metric\n",
    "# Penalize large errors\tMSE / RMSE\n",
    "# Interpret in original unit\tRMSE / MAE\n",
    "# Reduce outlier effect\tMAE\n",
    "# Model fit evaluation\tR²\n",
    "# Multiple features / avoid overfitting\tAdjusted R²"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5339f9a4-b4b7-47b9-aaf5-bd13a57d3db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | Condition / Requirement                 | Metric      | Reason                                    |\n",
    "# | --------------------------------------- | ----------- | ----------------------------------------- |\n",
    "# | Punish large errors                     | MSE / RMSE  | Squared error emphasizes large deviations |\n",
    "# | Interpret errors in original unit       | RMSE / MAE  | RMSE/MAE in same unit as target           |\n",
    "# | Reduce impact of outliers               | MAE         | Absolute error less sensitive to outliers |\n",
    "# | Model overall fit                       | R²          | Proportion of variance explained          |\n",
    "# | Multiple predictors / avoid overfitting | Adjusted R² | Penalizes irrelevant features             |\n",
    "# # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3808eeb-7eb7-4085-a0a3-937228a0cc70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification\n",
    "\n",
    "# Definition: Predicts discrete labels or categories.\n",
    "\n",
    "# Output: Finite, categorical. Examples:\n",
    "\n",
    "# “Yes” or “No” → binary classification\n",
    "\n",
    "# “Dog”, “Cat”, “Rabbit” → multi-class classification\n",
    "\n",
    "# Algorithms:\n",
    "\n",
    "# Logistic Regression (despite the name, used for classification)\n",
    "\n",
    "# Decision Trees\n",
    "\n",
    "# Random Forest (classification mode)\n",
    "\n",
    "# K-Nearest Neighbors (KNN)\n",
    "\n",
    "# Support Vector Machines (SVM)\n",
    "\n",
    "# Use cases:\n",
    "\n",
    "# Email spam detection (Spam / Not Spam)\n",
    "\n",
    "# Disease prediction (Sick / Healthy)\n",
    "\n",
    "# Image recognition (Cat / Dog / Bird)\n",
    "\n",
    "# 2. Regression\n",
    "\n",
    "# Definition: Predicts continuous numeric values.\n",
    "\n",
    "# Output: Real numbers. Examples:\n",
    "\n",
    "# Predicting house prices → ₹50 lakh, ₹75 lakh, etc.\n",
    "\n",
    "# Predicting temperature → 30°C, 22°C, etc.\n",
    "\n",
    "# Algorithms:\n",
    "\n",
    "# Linear Regression\n",
    "\n",
    "# Polynomial Regression\n",
    "\n",
    "# Random Forest (regression mode)\n",
    "\n",
    "# Support Vector Regression (SVR)\n",
    "\n",
    "# Use cases:\n",
    "\n",
    "# Predicting stock prices\n",
    "\n",
    "# Estimating car prices\n",
    "\n",
    "# Forecasting sales\n",
    "\n",
    "# Quick Rule of Thumb\n",
    "\n",
    "# If your target is a category → Classification\n",
    "\n",
    "# If your target is a number → Regression"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
